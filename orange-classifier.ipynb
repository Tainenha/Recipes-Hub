{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ae1bf2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-15T16:42:17.823871Z",
     "iopub.status.busy": "2025-01-15T16:42:17.823601Z",
     "iopub.status.idle": "2025-01-15T16:52:39.201448Z",
     "shell.execute_reply": "2025-01-15T16:52:39.200606Z"
    },
    "papermill": {
     "duration": 621.418001,
     "end_time": "2025-01-15T16:52:39.239041",
     "exception": false,
     "start_time": "2025-01-15T16:42:17.821040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1761 images belonging to 2 classes.\n",
      "Found 440 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 822ms/step - accuracy: 0.5322 - loss: 0.9572 - val_accuracy: 0.4279 - val_loss: 0.6958 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m 1/55\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5625 - loss: 0.8085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5625 - loss: 0.8085 - val_accuracy: 0.2917 - val_loss: 0.7006 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 459ms/step - accuracy: 0.4956 - loss: 0.9612 - val_accuracy: 0.4207 - val_loss: 0.6978 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 1.1564 - val_accuracy: 0.4167 - val_loss: 0.6977 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 461ms/step - accuracy: 0.4983 - loss: 0.9530 - val_accuracy: 0.4231 - val_loss: 0.7054 - learning_rate: 2.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3438 - loss: 1.0689 - val_accuracy: 0.3750 - val_loss: 0.7125 - learning_rate: 2.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 452ms/step - accuracy: 0.5050 - loss: 0.8810 - val_accuracy: 0.4255 - val_loss: 0.7160 - learning_rate: 2.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 1.2250 - val_accuracy: 0.3333 - val_loss: 0.7368 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 459ms/step - accuracy: 0.4998 - loss: 0.9269 - val_accuracy: 0.4255 - val_loss: 0.7228 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4062 - loss: 1.3720 - val_accuracy: 0.3333 - val_loss: 0.7478 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 482ms/step - accuracy: 0.4909 - loss: 0.9670 - val_accuracy: 0.4303 - val_loss: 0.7311 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.5938 - loss: 0.9944 - val_accuracy: 0.2500 - val_loss: 0.7928 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 461ms/step - accuracy: 0.4924 - loss: 0.9438 - val_accuracy: 0.4231 - val_loss: 0.7517 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6688 - val_accuracy: 0.3750 - val_loss: 0.7725 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 469ms/step - accuracy: 0.4857 - loss: 0.9079 - val_accuracy: 0.4111 - val_loss: 0.7481 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3438 - loss: 0.9856 - val_accuracy: 0.5833 - val_loss: 0.6794 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 456ms/step - accuracy: 0.5133 - loss: 0.9168 - val_accuracy: 0.4207 - val_loss: 0.7303 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.8173 - val_accuracy: 0.4167 - val_loss: 0.7321 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 459ms/step - accuracy: 0.4924 - loss: 0.9248 - val_accuracy: 0.4279 - val_loss: 0.7435 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 1.2010 - val_accuracy: 0.2917 - val_loss: 0.7992 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 454ms/step - accuracy: 0.5186 - loss: 0.9211 - val_accuracy: 0.4231 - val_loss: 0.7262 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.8978 - val_accuracy: 0.3750 - val_loss: 0.7410 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 457ms/step - accuracy: 0.4999 - loss: 0.9338 - val_accuracy: 0.4255 - val_loss: 0.7208 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5625 - loss: 0.7749 - val_accuracy: 0.3333 - val_loss: 0.7445 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 458ms/step - accuracy: 0.4963 - loss: 0.9532 - val_accuracy: 0.4183 - val_loss: 0.7138 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 0.9677 - val_accuracy: 0.4583 - val_loss: 0.7063 - learning_rate: 1.0000e-05\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 693ms/step - accuracy: 0.4662 - loss: 1.0129 - val_accuracy: 0.4231 - val_loss: 0.9406 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.6562 - loss: 0.6617 - val_accuracy: 0.3750 - val_loss: 1.0106 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 448ms/step - accuracy: 0.5167 - loss: 0.9629 - val_accuracy: 0.4255 - val_loss: 0.9697 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5312 - loss: 1.1076 - val_accuracy: 0.3333 - val_loss: 1.0842 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 454ms/step - accuracy: 0.4888 - loss: 1.0360 - val_accuracy: 0.4087 - val_loss: 0.7482 - learning_rate: 1.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.5625 - loss: 0.9547 - val_accuracy: 0.6250 - val_loss: 0.6620 - learning_rate: 1.0000e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 441ms/step - accuracy: 0.5555 - loss: 0.9329 - val_accuracy: 0.5889 - val_loss: 0.6784 - learning_rate: 1.0000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.9864 - val_accuracy: 0.4167 - val_loss: 0.7585 - learning_rate: 1.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 435ms/step - accuracy: 0.4976 - loss: 0.9696 - val_accuracy: 0.5769 - val_loss: 0.7026 - learning_rate: 1.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3750 - loss: 1.1599 - val_accuracy: 0.6250 - val_loss: 0.6691 - learning_rate: 1.0000e-05\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 514ms/step - accuracy: 0.2084 - loss: 0.8212\n",
      "Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Đường dẫn đến dữ liệu\n",
    "train_dir = '/kaggle/input/ai-training-challenge-hutech-orange-classifier/old_oranges_data_1/old_oranges_data/train_set' \n",
    "test_dir = '/kaggle/input/ai-training-challenge-hutech-orange-classifier/old_oranges_data_1/old_oranges_data/test_set'    \n",
    "# Tiền xử lý dữ liệu\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Tạo generator cho tập train và validation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập test\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Tính toán class weights để xử lý mất cân bằng dữ liệu\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Sử dụng EfficientNetB0 làm mô hình cơ sở\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Đóng băng các lớp của mô hình cơ sở\n",
    "\n",
    "# Thêm các lớp tùy chỉnh\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Tạo mô hình cuối cùng\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping, checkpoint, reduce_lr],\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "# Fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping, checkpoint, reduce_lr],\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "# Đánh giá mô hình trên tập test\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10639231,
     "sourceId": 90828,
     "sourceType": "competition"
    },
    {
     "datasetId": 6397903,
     "sourceId": 10333407,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6400087,
     "sourceId": 10343317,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 627.034239,
   "end_time": "2025-01-15T16:52:42.593345",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-15T16:42:15.559106",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
